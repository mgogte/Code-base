{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import time \n",
    "# for database operations\n",
    "from haversine import haversine\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_similarity_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "def ST_DBSCAN(points,max_distance,MinPts,dayRadius):\n",
    "    global visited \n",
    "    visited = []\n",
    "    noise = []\n",
    "    c_neighbors = []\n",
    "    cluster_id = 0\n",
    "    clusters = []\n",
    "    in_cluster = []\n",
    "    for p in points: \n",
    "        if p not in visited:\n",
    "            # neighbor_points = []\n",
    "            visited.append(p)\n",
    "            NeighborPts = regionQuery(p,points,max_distance,dayRadius)\n",
    "            if len(NeighborPts) < MinPts:\n",
    "                noise.append(p)\n",
    "            else:\n",
    "                cluster_id = cluster_id + 1\n",
    "                g = expandCluster(p,NeighborPts,max_distance,MinPts,in_cluster,cluster_id)\n",
    "                clusters.append(g)\n",
    "                c_neighbors=NeighborPts+[cluster_id]\n",
    "                #print c_neighbors\n",
    "                c_neighbors.append(g)\n",
    "    return clusters, c_neighbors\n",
    "\n",
    "#return len(NeighborPts)\n",
    "\n",
    "def expandCluster(p,NeighborPts,max_distance,MinPts,in_cluster,cluster_id):\n",
    "    in_cluster.append(p)\n",
    "    cluster = []\n",
    "    t_p = list(p) + [cluster_id]\n",
    "    cluster.append(t_p)\n",
    "    for point in NeighborPts:\n",
    "        if point not in visited:\n",
    "            visited.append(point)\n",
    "            new_neighbors = regionQuery(point,points,max_distance,dayRadius)\n",
    "            if len(new_neighbors) >= MinPts: \n",
    "                new_neighbors.append(NeighborPts)\n",
    "            if point not in in_cluster:\n",
    "                 t_point = list(point) + [cluster_id]\n",
    "                 in_cluster.append(point)\n",
    "                 cluster.append(t_point)\n",
    "    return cluster\n",
    "\n",
    "\n",
    "def regionQuery(p,points,max_distance,dayRadius):\n",
    "    neighbor_points = []\n",
    "    loc1 = (p[0],p[1])\n",
    "    for j in points:\n",
    "        if j != p:\n",
    "            # print 'P is %s and j is %s' % (p[0],j[0])\n",
    "            if abs(p[2]-j[2]) < dayRadius:\n",
    "                loc2 = (j[0],j[1])\n",
    "                dist = haversine(loc1, loc2)\n",
    "                if dist <= max_distance:\n",
    "                    neighbor_points.append(j)\n",
    "    neighbor_points.append(p) \n",
    "    return neighbor_points   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3\n",
    "max_distance = 80\n",
    "MaxPts = 10\n",
    "dayRadius = 10\n",
    "\n",
    "df = pd.DataFrame.from_csv('D:/Nanohub/results/data extract from database/in_STDB_2014_2.csv', sep ='\\t', encoding = 'UTF-8', header = None)\n",
    "df.columns = ['ip','resource_id','datetime','latitude','longitude','child_id','title', 'ip_domainname', 'ip_country', 'uidNumber']\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.sort_values(by = 'resource_id', axis = 0, ascending = True, na_position ='first')\n",
    "df_no_dups = df.drop_duplicates(subset = ['ip','resource_id'], keep = 'first')\n",
    "doy = []\n",
    "for date in df['datetime']:\n",
    "    doy.append(date.dayofyear)\n",
    "df['DoY'] = doy\n",
    "\n",
    "df_10 = df[df.groupby('resource_id').cumcount(ascending=False) >= 10]\n",
    "distinct_resources = list(df_10['resource_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4\n",
    "uniq_ip_2015 = df_10['ip'].unique()\n",
    "uniq_res_2015 = df_10['resource_id'].unique()\n",
    "sims = np.zeros((len(uniq_res_2015),len(uniq_ip_2015)))\n",
    "uniq_ip_2015.sort()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1505, 11211)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5 STDBSCAN call\n",
    "for l in distinct_resources: #range(21095,22000):\n",
    "    df_filtered = df_10[df_10['resource_id'] == l]\n",
    "    df_filtered =df_filtered[df_filtered['latitude'] > 0]\n",
    "    tups = df_filtered.set_index(['latitude'])[['longitude','DoY','resource_id','ip']].to_records().tolist()\n",
    "    points = tups\n",
    "    core, neigh = ST_DBSCAN(points,max_distance,MaxPts,dayRadius)\n",
    "    \n",
    "    fname = 'D:/Nanohub/results/GIS6/' + str(l) +'.csv'\n",
    "    \n",
    "    f = open(fname, 'wt')\n",
    "    try:\n",
    "        writer = csv.writer(f, lineterminator = '\\n')\n",
    "        #writer.writerow( ('Latitude', 'Longitude', 'DoY' , 'res_id' , 'cluster_id') )\n",
    "\n",
    "        for j in range(len(core)):\n",
    "            for i in range(len(core[j])):\n",
    "                    writer.writerow( core[j][i] )\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#6 similarity matrix\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for k in range(len(uniq_res_2015)):\n",
    "    fstr = Path('D:/Nanohub/results/GIS6/' + str(uniq_res_2015[k]) + '.csv')\n",
    "    if fstr.is_file():\n",
    "        df_open = pd.DataFrame.from_csv(fstr, sep =',', encoding = 'UTF-8', header = None)\n",
    "        df_open.columns = ['longitude','DOY','resource_id','ip','cluster_id']\n",
    "        ips_of_file = df_open['ip'].unique()\n",
    "        ips_of_file.sort()\n",
    "        if len(df_open) > 0:\n",
    "            for j in range(len(ips_of_file)):\n",
    "                for i in range(len(uniq_ip_2015)):\n",
    "                    if ips_of_file[j] == uniq_ip_2015[i]:\n",
    "                        sims[k][i] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(sims[1][90:200])\n",
    "print(uniq_res_2015[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#7 incorrect\n",
    "\n",
    "for s1 in range(len(sims)):\n",
    "    #print ('s1',uniq_res_2015[s1])\n",
    "    arr1 = []\n",
    "    for s2 in range(len(sims)):\n",
    "        if s2 != s1:\n",
    "            if jaccard_similarity_score(sims[s1],sims[s2]) > 0.8:\n",
    "                arr1.append(uniq_res_2015[s2])\n",
    "    print('---------------------------------------------------')            \n",
    "    print (len(arr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 [126, 131]\n",
      "126 [125, 130, 131]\n",
      "130 [126, 131, 3585]\n",
      "131 [125, 126, 130]\n",
      "135 [924, 988]\n",
      "222 [9525]\n",
      "416 [4962]\n",
      "924 [135, 988]\n",
      "988 [135, 924]\n",
      "1514 [22879]\n",
      "1840 [1845, 5307, 5309, 12707]\n",
      "1845 [1840, 5307, 5309, 12707]\n",
      "3059 [13159, 17282, 22329]\n",
      "3585 [130]\n",
      "4754 [4757]\n",
      "4757 [4754]\n",
      "4962 [416]\n",
      "5307 [1840, 1845, 5309, 12707]\n",
      "5309 [1840, 1845, 5307, 12707]\n",
      "6806 [7486]\n",
      "7320 [21880]\n",
      "7486 [6806]\n",
      "7780 [7827, 12456]\n",
      "7827 [7780, 12456]\n",
      "8742 [10165, 10226]\n",
      "9109 [17591]\n",
      "9162 [9167]\n",
      "9167 [9162]\n",
      "9208 [9231, 9525]\n",
      "9231 [9208, 9525]\n",
      "9525 [222, 9208, 9231]\n",
      "10165 [8742]\n",
      "10226 [8742]\n",
      "12453 [12456, 12457]\n",
      "12456 [7780, 7827, 12453, 12457]\n",
      "12457 [12453, 12456]\n",
      "12707 [1840, 1845, 5307, 5309]\n",
      "13159 [3059, 17282, 19169, 22329, 23261]\n",
      "13554 [16362]\n",
      "14264 [16221]\n",
      "16221 [14264]\n",
      "16362 [13554]\n",
      "16511 [16546]\n",
      "16545 [16546]\n",
      "16546 [16511, 16545]\n",
      "16548 [16608]\n",
      "16608 [16548, 16774, 16789]\n",
      "16703 [19299]\n",
      "16774 [16608, 16789]\n",
      "16789 [16608, 16774]\n",
      "16887 [16895, 16896]\n",
      "16895 [16887, 16896, 16920, 16965, 17028, 17293, 17295]\n",
      "16896 [16887, 16895]\n",
      "16920 [16895, 16965, 17293, 17295]\n",
      "16965 [16895, 16920, 17293, 17295]\n",
      "17028 [16895, 17293]\n",
      "17282 [3059, 13159, 22329, 23261]\n",
      "17293 [16895, 16920, 16965, 17028, 17295]\n",
      "17295 [16895, 16920, 16965, 17293]\n",
      "17591 [9109]\n",
      "18616 [18867, 21367]\n",
      "18867 [18616, 21367]\n",
      "19169 [13159]\n",
      "19299 [16703]\n",
      "19478 [20260]\n",
      "20260 [19478]\n",
      "21367 [18616, 18867]\n",
      "21880 [7320]\n",
      "22329 [3059, 13159, 17282]\n",
      "22879 [1514]\n",
      "23261 [13159, 17282]\n"
     ]
    }
   ],
   "source": [
    "fjacc = open('D:/Nanohub/results/GIS6/jacc6.csv','w')\n",
    "for s1 in range(len(sims)):\n",
    "    a1 = sims[s1]\n",
    "    arr1 = []\n",
    "    jacc = -1\n",
    "    for s2 in range(len(sims)):\n",
    "        if s1!=s2:\n",
    "            a2 = sims[s2]\n",
    "            inter_1 = 0\n",
    "            all_1 = 0\n",
    "            for i in range(len(a1)):\n",
    "                all_1 = all_1 + a1[i] + a2[i]\n",
    "                if a1[i] == a2[i] and a1[i] == 1:\n",
    "                    inter_1 += 1\n",
    "                if all_1-inter_1 >0:\n",
    "                    jacc = float(float(inter_1) / float(all_1-inter_1))\n",
    "        \n",
    "            if jacc > 0.5 and jacc != -1:\n",
    "                arr1.append(uniq_res_2015[s2])\n",
    "    if len(arr1)!=0:\n",
    "        print (uniq_res_2015[s1],arr1)\n",
    "    \n",
    "    '''if len(arr1) > 0:\n",
    "       \n",
    "        writer = csv.writer(fjacc, lineterminator = '\\n')\n",
    "        writer.writerow(arr1 )'''        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
